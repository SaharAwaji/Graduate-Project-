# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_-97MVy7hip_zfwEow3PiaAu4ZM0jllp
"""

# Library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
#!pip install streamlit plotly
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
#!pip install statsmodels
import statsmodels.api as sm
import statsmodels

meta_rows2 = [
    {"indicator_id": "EMPLOY_RATE_6_12M", "name": "معدل توظيف الخريجين خلال 6–12 شهرًا", "component_details": "Outcomes-Employment","component": "Outcomes","component": "Outcomes", "weight": 0.18, "function": "Lagging", "goal": 4, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "EMPLOYER_SATISFACTION", "name": "معدل رضا أصحاب العمل عن الخريجين", "component_details": "Outcomes-Employment","component": "Outcomes", "weight": 0.14, "function": "Concurrent", "goal": 1, "direction": "HigherIsBetter", "is_likert": True},
    {"indicator_id": "PROGRAMS_INTL_RANKED", "name": "نسبة البرامج المصنفة دوليًا", "component_details": "Outcomes-Employment","component": "Outcomes",  "weight": 0.03, "function": "Leading", "goal": 1, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "CAREER_SERVICES", "name": "عدد المشاريع الريادية المحتضنة/المعتمدة", "component_details": "Outcomes-Innovation& entrepreneurship", "component": "Outcomes", "weight": 0.04, "function": "Leading", "goal": 3, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "PATENT_COUNT", "name": "عدد براءات الاختراع", "component_details": "Outcomes-Innovation& entrepreneurship","component": "Outcomes", "weight": 0.02, "function": "Leading", "goal": 3, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "BIZ_PARTNERSHIPS", "name": "نسبة الطلبة في برامج STEMM (مع الصحة)", "component_details": "Processes- Education&traning",  "component": "Processess","weight": 0.04, "function": "Leading", "goal": 3, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "NATIONAL_PROF_EXAMS", "name": "معدل الأداء الأكاديمي في مواد التخصص الأساسية", "component_details": "Processes- Education&traning", "component": "Processess", "weight": 0.06, "function": "Concurrent", "goal": 2, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "LINKEDIN_ACTIVE", "name": "معدل التخرج في الوقت المحدد", "component_details": "Processes- Education&traning", "component": "Processess", "weight": 0.06, "function": "Lagging", "goal": 2, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "WAGE_GROWTH_1Y", "name": "نسبة النجاح في الاختبارات المعيارية الموحدة", "component_details": "Processes- Education&traning",  "component": "Processess","weight":0.06, "function": "Lagging", "goal": 2, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "FOUNDERS_RATE", "name": "نتائج الاختبارات الوطنية/المهنية", "component_details": "Processes- Education&traning", "component": "Processess", "weight": 0.05, "function": "Lagging", "goal": 2, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "PROMOTION_RATE", "name": "دعم الخريجين بخدمات الإرشاد المهني", "component_details": "Processes- Support & empowerment", "component": "Processess", "weight": 0.04, "function": "Leading", "goal": 1, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "JOB_STABILITY_2Y", "name": "نسبة البرامج المشتركة مع قطاع الأعمال", "component_details": "Processes- Support & empowerment",  "component": "Processess","weight": 0.1, "function": "Leading", "goal": 1, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "STEMM_SHARE", "name": "نسبة الطلبة المشاركين في مبادرات الابتكار", "component_details": "Processes- Support & empowerment", "component": "Processess", "weight": 0.04, "function": "Leading", "goal": 3, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "ACCRED_PROGS", "name": "رضا الطلبة عن العملية التعليمية", "component_details": "Processes- Support & empowerment", "component": "Processess", "weight": 0.03, "function": "Concurrent", "goal": 2, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "INTERN_RATE", "name": "رضا الطلبة عن الخدمات المساندة", "component_details": "Processes- Support & empowerment", "component": "Processess", "weight": 0.03, "function": "Concurrent", "goal": 2, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "ENTRE_SUPPORT", "name": "البرامج الأكاديمية المعززة لمفهوم ريادة الأعمال", "component_details": "Processes-Supportive academic programs","component": "Processes", "weight": 0.03, "function": "Leading", "goal": 3, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "FUNDING_SHARE", "name": "البرامج المدمجة بمهارات القرن 21", "component_details": "Processes-Supportive academic programs",  "component": "Processess","weight": 0.03, "function": "Leading", "goal": 3, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "STUDENT_SAT", "name": "البرامج المدمجة بمفاهيم الاستدامة", "component_details": "Processes-Supportive academic programs", "component": "Processess","weight": 0.03, "function": "Leading", "goal": 3, "direction": "HigherIsBetter", "is_likert": True},
    {"indicator_id": "GRAD_SAT", "name": "السجل المهاري (Skills Portfolio)", "component_details": "Conceptual-Human","component": "Conceptual",  "weight": 0.02, "function": "Concurrent", "goal": 2, "direction": "HigherIsBetter", "is_likert": True},
    {"indicator_id": "SKILL_DEV", "name": "الشهادات الاحترافية", "component_details": "Conceptual-Human", "component": "Conceptual", "weight": 0.02, "function": "Concurrent", "goal": 2, "direction": "HigherIsBetter", "is_likert": True},
    {"indicator_id": "RESEARCH_PUBS", "name": "المشاركة في المؤتمرات/المسابقات", "component_details": "Conceptual-Human","component": "Conceptual",  "weight": 0.02, "function": "Concurrent", "goal": 2, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "INTERNATIONAL_STUD", "name": "المشاركة في الأندية الطلابية", "component_details": "Conceptual-Social &professional", "component": "Conceptual", "weight": 0.01, "function": "Leading", "goal": 1, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "FACULTY_INTL", "name": "المشاركة في التطوع وخدمة المجتمع", "component_details": "Conceptual-Social &professional","component": "Conceptual",  "weight": 0.01, "function": "Leading", "goal": 1, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "MOBILITY", "name": "الحسابات المهنية النشطة (LinkedIn)", "component_details": "Conceptual-Social &professional", "component": "Conceptual", "weight": 0.04, "function": "Leading", "goal": 1, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "NATIONAL_PART", "name": "كفاءة اللغة الإنجليزية أو لغات أجنبية", "component_details": "Conceptual-Human", "component": "Conceptual", "weight": 0.02, "function": "Concurrent", "goal": 2, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "CURRICULUM_UPD", "name": "متوسط نسبة الزيادة في الرواتب بعد سنة", "component_details": "Impact","component": "Impact",  "weight": 0.12, "function": "Lagging", "goal": 4, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "ENTRE_SUPPORT", "name": "نسبة الخريجين المؤسسين لمشاريع ريادية", "component_details": "Impact","component": "Impact",  "weight": 0.06, "function": "Lagging", "goal": 4, "direction": "HigherIsBetter", "is_likert": False},
    {"indicator_id": "EMPLOYABILITY_SKILL", "name": "معدل الترقيات الوظيفية للخريجين", "component_details": "Impact", "component": "Impact", "weight": 0.06, "function": "Lagging", "goal": 4, "direction": "HigherIsBetter", "is_likert": True},
    {"indicator_id": "COMM_SKILLS", "name": "الاستقرار الوظيفي", "component_details": "Impact","component": "Impact",  "weight": 0.06, "function": "Lagging", "goal": 4, "direction": "HigherIsBetter", "is_likert": True},
    {"indicator_id": "DIGITAL_SKILLS", "name": "السمعة المجتمعية لمخرجات الجامعة", "component_details": "Impact","component": "Impact",  "weight": 0.04, "function": "Lagging", "goal": 1, "direction": "HigherIsBetter", "is_likert": True},
]

indicators_meta2 = pd.DataFrame(meta_rows2)
#indicators_meta2
# إعادة التطبيع بحيث يكون المجموع = 1
indicators_meta2["weight"] = indicators_meta2["weight"] / indicators_meta2["weight"].sum()

# التحقق بعد التطبيع
print("New total for Weight =", indicators_meta2["weight"].sum())

# -----------------------------

#SAMUILATE
np.random.seed(42)
years = [2021, 2022, 2023, 2024]
universities = ["UniA", "UniB", "UniC"]

def likert_to_100(x): return ((x - 1) / 4.0) * 100.0

def minmax_0_100(series, higher_is_better=True):
    s = series.astype(float)
    vmin, vmax = s.min(), s.max()
    norm = (s - vmin) / (vmax - vmin) * 100.0 if vmax > vmin else pd.Series(50.0, index=s.index)
    return norm if higher_is_better else 100.0 - norm


def slope(series):
    years_sorted = sorted(series.keys())
    diffs = [series[b]-series[a] for a,b in zip(years_sorted[:-1], years_sorted[1:])]
    return np.mean(diffs) if diffs else np.nan

def classify_trend(s):
    if pd.isna(s): return "N/A"
    if s >= 5: return "Strong Uptrend"
    if 2 <= s < 5: return "Mild Uptrend"
    if -1.9 <= s <= 1.9: return "Flat"
    if -5 < s < -2: return "Mild Downtrend"
    if s <= -5: return "Strong Downtrend"
    return "Flat"

# --------------------------
# حساب المؤشر الكلي لكل نوع
# --------------------------
np.random.seed(42)
if 'value' not in indicators_meta2.columns:
    indicators_meta2['value'] = np.random.rand(len(indicators_meta2))

indices_df = (
    indicators_meta2
      .assign(wv = indicators_meta2['value'] * indicators_meta2['weight'])
      .groupby('function', as_index=False)['wv'].sum()
      .rename(columns={'wv': 'Index'})
)

# إضافة المؤشر الكلي
overall_index = indices_df['Index'].sum()
indices_df = pd.concat([indices_df, pd.DataFrame([{'function': 'Overall', 'Index': overall_index}])], ignore_index=True)

print(indices_df)

# Functions

np.random.seed(42)
years = [2021, 2022, 2023, 2024]
universities = ["UniA", "UniB", "UniC"]

def likert_to_100(x): return ((x - 1) / 4.0) * 100.0

def minmax_0_100(series, higher_is_better=True):
    s = series.astype(float)
    vmin, vmax = s.min(), s.max()
    norm = (s - vmin) / (vmax - vmin) * 100.0 if vmax > vmin else pd.Series(50.0, index=s.index)
    return norm if higher_is_better else 100.0 - norm


def slope(series):
    years_sorted = sorted(series.keys())
    diffs = [series[b]-series[a] for a,b in zip(years_sorted[:-1], years_sorted[1:])]
    return np.mean(diffs) if diffs else np.nan

def slope_from_series(year_to_value: dict) -> float:
    """ميل بسيط عبر فروقات سنوية متتالية."""
    if not year_to_value:
        return np.nan
    years_sorted = sorted(year_to_value.keys())
    diffs = [year_to_value[b] - year_to_value[a] for a,b in zip(years_sorted[:-1], years_sorted[1:])]
    return float(np.mean(diffs)) if diffs else np.nan

def classify_trend5(s):
    if pd.isna(s): return "Steady"
    if s >= 5: return "High Upper Trend"
    if 2 <= s < 5: return "Moderate Upper Trend"
    if -1.9 <= s <= 1.9: return "Steady"
    if -5 < s < -2: return "Moderate Lower Trend"
    if s <= -5: return "High Lower Trend"
    return "Steady"

# لتفسير "Steady" حسب المستوى (مرتفع/متوسط/منخفض) إن احتجت
def level_bucket(x):
    if pd.isna(x): return "Unknown"
    if x >= 75: return "High"
    if x >= 50: return "Mid"
    return "Low"

def aggregate(df, by_cols):
    grouped = []
    for keys, sub in df.groupby(by_cols):
        v = sub["norm_0_100"].to_numpy(dtype=float)
        w = sub["weight"].to_numpy(dtype=float)

        den = w.sum()
        if den == 0:
            raise ValueError(f"الأوزان = 0 في المجموعة {keys} → شي غلط بالبيانات")

        val = (v @ w) / den  # حاصل ضرب داخلي ÷ مجموع الأوزان

        rec = dict(zip(by_cols, keys if isinstance(keys, tuple) else (keys,)))
        rec["score"] = val
        grouped.append(rec)
    return pd.DataFrame(grouped)

# -----------------------------
# 3) محاكاة بيانات خام
# -----------------------------
raw = []
rng = np.random.default_rng(2025)
for uni in universities:
    for y in years:
        for _, row in indicators_meta2.iterrows():
            if row["is_likert"]:
                val = rng.uniform(2.5, 4.7)  # ليكرت 1–5
            else:
                val = rng.uniform(40, 95)    # نسب مئوية
            raw.append((uni, y, row["indicator_id"], val))
raw_df = pd.DataFrame(raw, columns=["university","year","indicator_id","raw_value"])

# -----------------------------
# 4) التطبيع
# -----------------------------
norm_rows = []
for ind, sub in raw_df.groupby("indicator_id"):
    meta = indicators_meta2[indicators_meta2["indicator_id"]==ind].iloc[0]
    higher = (meta["direction"] != "LowerIsBetter")
    sub = sub.copy()
    if meta["is_likert"]:
        sub["norm_0_100"] = likert_to_100(sub["raw_value"])
    else:
        sub["norm_0_100"] = minmax_0_100(sub["raw_value"], higher)
    norm_rows.append(sub)
norm_df = pd.concat(norm_rows)


# -----------------------------
# 5)
# -----------------------------
merged = norm_df.merge(indicators_meta2, on="indicator_id")
merged["weight"] = merged["weight"].fillna(0.0)

# -----------------------------
# 6)
# -----------------------------

# 1) مستوى الوظيفة داخل الهدف (weighted by indicator weights)
func_level = (
    merged
    .assign(wv = merged["norm_0_100"] * merged["weight"])
    .groupby(["university","year","goal","function"], as_index=False)
    .agg(score_sum=("wv","sum"), wsum=("weight","sum"))
    .assign(score = lambda d: np.where(d["wsum"]>0, d["score_sum"]/d["wsum"], np.nan))
    .drop(columns=["score_sum"])
)

# 2) مستوى الهدف (weighted by total weights carried from functions)
goal_level = (
    func_level
    .assign(wv = func_level["score"] * func_level["wsum"])
    .groupby(["university","year","goal"], as_index=False)
    .agg(score_sum=("wv","sum"), wsum=("wsum","sum"))
    .assign(score = lambda d: np.where(d["wsum"]>0, d["score_sum"]/d["wsum"], np.nan))
    .drop(columns=["score_sum"])
)

# 3) المستوى الإجمالي (weighted by total weights carried from goals)
overall = (
    goal_level
    .assign(wv = goal_level["score"] * goal_level["wsum"])
    .groupby(["university","year"], as_index=False)
    .agg(score_sum=("wv","sum"), wsum=("wsum","sum"))
    .assign(overall_index_0_100 = lambda d: np.where(d["wsum"]>0, d["score_sum"]/d["wsum"], np.nan))
    .drop(columns=["score_sum","wsum"])
)

# ===============================
# 1) التجميع الموزون المتسلسل
#    (يحمل أوزان المؤشرات حتى القمة)
# ===============================
# merged يجب أن يحتوي columns: ['university','year','goal','function','indicator_id','norm_0_100','weight', ...]
# تأكد من عدم وجود أوزان NaN
if merged['weight'].isna().any():
    raise ValueError("يوجد مؤشرات بلا وزن. عالجها قبل المتابعة (مثلاً fillna أو تعريف الأوزان).")

# مستوى الوظيفة داخل الهدف: وزن بالمؤشرات
func_level = (
    merged
    .assign(wv = merged["norm_0_100"] * merged["weight"])
    .groupby(["university","year","goal","function"], as_index=False)
    .agg(score_sum=("wv","sum"), wsum=("weight","sum"))
    .assign(score = lambda d: np.where(d["wsum"]>0, d["score_sum"]/d["wsum"], np.nan))
    .drop(columns=["score_sum"])
)

# مستوى الهدف: وزن بمجاميع أوزان الوظائف (المحمولة من المؤشرات)
goal_level = (
    func_level
    .assign(wv = func_level["score"] * func_level["wsum"])
    .groupby(["university","year","goal"], as_index=False)
    .agg(score_sum=("wv","sum"), wsum=("wsum","sum"))
    .assign(score = lambda d: np.where(d["wsum"]>0, d["score_sum"]/d["wsum"], np.nan))
    .drop(columns=["score_sum"])
)

# المستوى الكلي: وزن بمجاميع أوزان الأهداف
overall = (
    goal_level
    .assign(wv = goal_level["score"] * goal_level["wsum"])
    .groupby(["university","year"], as_index=False)
    .agg(score_sum=("wv","sum"), wsum=("wsum","sum"))
    .assign(overall_index_0_100 = lambda d: np.where(d["wsum"]>0, d["score_sum"]/d["wsum"], np.nan))
    .drop(columns=["score_sum","wsum"])
)

# ===============================
# 2) مصفوفة (الاتجاه × الوظيفة) لإنتاج الرؤى
# ===============================
MATRIX = {
    ("Leading",   "High Upper Trend"):   {"ar_i":"فرصة قوية قادمة","ar_a":"ضاعف الاستثمار وعجّل المبادرات الوقائية/التمكينية","en_i":"Strong upcoming opportunity","en_a":"Double down on investments and accelerate enabling programs","prio":"High"},
    ("Leading",   "Moderate Upper Trend"):{"ar_i":"فرصة محتملة","ar_a":"راقب عن كثب وقدّم دعماً مستهدفاً","en_i":"Potential opportunity","en_a":"Monitor closely and provide targeted support","prio":"Medium"},
    ("Leading",   "Steady"):              {"ar_i":"لا إشارات جديدة","ar_a":"استمر بالمراقبة والتحقق الدوري","en_i":"No new signals","en_a":"Maintain monitoring and periodic checks","prio":"Low"},
    ("Leading",   "Moderate Lower Trend"):{ "ar_i":"تهديد محتمل","ar_a":"جهّز خطط احتواء مبكر وحدّد الأسباب الجذرية","en_i":"Potential threat","en_a":"Prepare early containment plans and identify root causes","prio":"High"},
    ("Leading",   "High Lower Trend"):   {"ar_i":"إنذار مبكر قوي","ar_a":"تدخّل فوري لتصحيح المسار وإعادة توزيع الموارد","en_i":"Strong early-warning signal","en_a":"Immediate intervention to correct course and reallocate resources","prio":"Critical"},
    ("Concurrent","High Upper Trend"):   {"ar_i":"أداء حالي ممتاز","ar_a":"عمّم أفضل الممارسات واستثمر للحفاظ على المستوى","en_i":"Excellent current performance","en_a":"Scale best practices and invest to sustain level","prio":"High"},
    ("Concurrent","Moderate Upper Trend"):{"ar_i":"تحسن مستمر","ar_a":"واصل الدعم وحسّن تدريجياً","en_i":"Continuous improvement","en_a":"Continue support and drive incremental improvement","prio":"Medium"},
    ("Concurrent","Steady"):             {"ar_i":"استقرار الوضع","ar_a":"حافظ على الوضع وراقب مؤشرات المخاطر","en_i":"Stable situation","en_a":"Maintain status and monitor risk indicators","prio":"Low"},
    ("Concurrent","Moderate Lower Trend"):{"ar_i":"ضعف آني","ar_a":"عالج الأسباب المباشرة وحدّد الثغرات التشغيلية","en_i":"Current weakening","en_a":"Address immediate causes and close operational gaps","prio":"High"},
    ("Concurrent","High Lower Trend"):   {"ar_i":"تدهور حاد الآن","ar_a":"استجابة عاجلة وخطة تصحيح قصيرة الأجل","en_i":"Acute current deterioration","en_a":"Urgent response and short-term recovery plan","prio":"Critical"},
    ("Lagging",  "High Upper Trend"):    {"ar_i":"نتائج قوية متحققة","ar_a":"وثّق النجاحات وعمّم السياسات الفعّالة","en_i":"Strong realized results","en_a":"Document wins and scale effective policies","prio":"Medium"},
    ("Lagging",  "Moderate Upper Trend"):{ "ar_i":"أثر إيجابي واضح","ar_a":"حافظ على الاستراتيجية وحسّن الكفاءة","en_i":"Clear positive impact","en_a":"Sustain strategy and improve efficiency","prio":"Medium"},
    ("Lagging",  "Steady"):              {"ar_i":"أثر مستقر","ar_a":"لا تغييرات استراتيجية؛ راقب لتحوّلات محتملة","en_i":"Stable impact","en_a":"No strategic changes; keep watch for shifts","prio":"Low"},
    ("Lagging",  "Moderate Lower Trend"):{ "ar_i":"أثر ضعيف بدأ يظهر","ar_a":"قيّم جودة التنفيذ وارتباطه بالمدخلات","en_i":"Emerging weak impact","en_a":"Evaluate execution quality and input-output linkage","prio":"High"},
    ("Lagging",  "High Lower Trend"):    {"ar_i":"أثر سلبي مؤكد","ar_a":"مراجعة شاملة للاستراتيجية ومكونات التنفيذ","en_i":"Confirmed negative impact","en_a":"Comprehensive review of strategy and execution","prio":"Critical"},
}
PRIO_SCORE = {"Critical":3, "High":2, "Medium":1, "Low":0}

# ===============================
# 3) حساب الاتجاه الخماسي وإسقاط المصفوفة
#    (أ) على مستوى الجامعة × الوظيفة
# ===============================
func_insights = []
for (uni, fn), sub in func_level.groupby(["university","function"]):
    # ميل عبر السنوات
    y2v = {int(r["year"]): float(r["score"]) for _, r in sub.sort_values("year").iterrows()}
    s = slope_from_series(y2v)
    t5 = classify_trend5(s)
    # آخر سنة/قيمة لعرضها
    last_row = sub.loc[sub["year"].idxmax()]
    last_year = int(last_row["year"])
    last_score = float(last_row["score"])

    item = MATRIX.get((fn, t5), None)
    if item is None:
        # لو عندك تهجئة مختلفة للوظائف، تأكد منها
        item = {"ar_i":"—","ar_a":"—","en_i":"—","en_a":"—","prio":"Low"}

    func_insights.append({
        "university": uni,
        "function": fn,
        "trend5": t5,
        "slope": s,
        "latest_year": last_year,
        "latest_score": last_score,
        "interpretation_ar": item["ar_i"],
        "action_ar": item["ar_a"],
        "interpretation_en": item["en_i"],
        "action_en": item["en_a"],
        "priority": item["prio"],
        "priority_score": PRIO_SCORE[item["prio"]],
    })
func_insights_df = pd.DataFrame(func_insights).sort_values(
    ["university","priority_score","function"], ascending=[True, False, True]
).reset_index(drop=True)

# ===============================
#    (ب) على مستوى الجامعة × الهدف × الوظيفة
# ===============================
func_goal_insights = []
for (uni, goal, fn), sub in func_level.groupby(["university","goal","function"]):
    y2v = {int(r["year"]): float(r["score"]) for _, r in sub.sort_values("year").iterrows()}
    s = slope_from_series(y2v)
    t5 = classify_trend5(s)
    last_row = sub.loc[sub["year"].idxmax()]
    last_year = int(last_row["year"]); last_score = float(last_row["score"])

    item = MATRIX.get((fn, t5), {"ar_i":"—","ar_a":"—","en_i":"—","en_a":"—","prio":"Low"})
    func_goal_insights.append({
        "university": uni, "goal": int(goal), "function": fn,
        "trend5": t5, "slope": s,
        "latest_year": last_year, "latest_score": last_score,
        "interpretation_ar": item["ar_i"], "action_ar": item["ar_a"],
        "interpretation_en": item["en_i"], "action_en": item["en_a"],
        "priority": item["prio"], "priority_score": PRIO_SCORE[item["prio"]],
    })
func_goal_insights_df = pd.DataFrame(func_goal_insights).sort_values(
    ["university","goal","priority_score"], ascending=[True, True, False]
).reset_index(drop=True)

# ===============================
#    (ج) اتجاه للمستوى الكلي والهدف فقط (بدون وظيفة)
# ===============================
# اتجاه الكلي:
overall_trends = []
for uni, sub in overall.groupby("university"):
    y2v = {int(r["year"]): float(r["overall_index_0_100"]) for _, r in sub.sort_values("year").iterrows()}
    s = slope_from_series(y2v)
    t5 = classify_trend5(s)
    last_row = sub.loc[sub["year"].idxmax()]
    overall_trends.append({
        "university": uni,
        "trend5": t5,
        "slope": s,
        "latest_year": int(last_row["year"]),
        "overall_now": float(last_row["overall_index_0_100"]),
        "level_bucket": level_bucket(float(last_row["overall_index_0_100"]))
    })
overall_insights_df = pd.DataFrame(overall_trends)

# اتجاه لكل هدف:
goal_trends = []
for (uni, goal), sub in goal_level.groupby(["university","goal"]):
    y2v = {int(r["year"]): float(r["score"]) for _, r in sub.sort_values("year").iterrows()}
    s = slope_from_series(y2v)
    t5 = classify_trend5(s)
    last_row = sub.loc[sub["year"].idxmax()]
    goal_trends.append({
        "university": uni, "goal": int(goal),
        "trend5": t5, "slope": s,
        "latest_year": int(last_row["year"]),
        "score_now": float(last_row["score"]),
        "level_bucket": level_bucket(float(last_row["score"]))
    })
goal_insights_df = pd.DataFrame(goal_trends)

# ===============================
# 4) ملخص تنفيذي سريع (نص تلقائي لكل جامعة)
# ===============================
def make_executive_brief(uni):
    parts = []
    row = overall_insights_df[overall_insights_df["university"]==uni]
    if not row.empty:
        t = row.iloc[0]
        parts.append(f"المؤشر الكلي: {t['overall_now']:.1f}/100 ({t['trend5']}, مستوى {t['level_bucket']}).")
    # أهم 3 تنبيهات حسب الوظيفة
    top3 = func_insights_df[func_insights_df["university"]==uni].nlargest(3, "priority_score")
    if not top3.empty:
        for _, r in top3.iterrows():
            parts.append(f"- {r['function']} • {r['trend5']} • {r['interpretation_ar']} → {r['action_ar']}")
    return "\n".join(parts) if parts else "لا تتوفر بيانات كافية."

# مثال طباعة موجز لكل جامعة:
for u in sorted(overall["university"].unique()):
    print(f"\n🧭 {u}\n{make_executive_brief(u)}")


# ===============================
# 5) (اختياري) تكامل سريع مع Streamlit
# ===============================
# ======== IMPORTS الضرورية ========
import numpy as np, pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from statsmodels.tsa.holtwinters import ExponentialSmoothing

# ======== عنوان الصفحة ========
st.set_page_config(page_title="Overall Graduate Readiness Index", layout="wide")
st.title("📈 الداشبورد: المؤشر الكلي لجاهزية الخريجين")
st.caption("Gauge للمؤشر الكلي • Pie لمساهمة الوظائف • Trend عبر السنوات • 👨‍🎓 عدّاد الطلاب + تنبؤ وطني")

# ======== تجهيز بيانات الطلاب (إن لم تتوفر) ========
if 'students_df' not in globals() or students_df is None or students_df.empty:
    # نبني بيانات طلاب تجريبية متوافقة مع جامعات وسنوات overall
    rng = np.random.default_rng(42)
    universities_ = sorted(overall["university"].unique().tolist())
    years_ = sorted(overall["year"].unique().tolist())
    srows = []
    for y in years_:
        national_total = int(rng.integers(24000, 36000))
        shares = rng.random(len(universities_)); shares /= shares.sum()
        for u, sh in zip(universities_, shares):
            srows.append((u, y, int(national_total * sh)))
    students_df = pd.DataFrame(srows, columns=["university","year","students"])

# ======== 1) المرشحات ========
left, right = st.columns([1,1])
with left:
    universities = sorted(overall["university"].unique().tolist())
    uni = st.selectbox("اختر الجامعة", universities, index=0)
with right:
    years = sorted(overall["year"].unique().tolist())
    year_start, year_end = st.select_slider("نطاق السنوات للترند", options=years, value=(years[0], years[-1]))
current_year = year_end

# إطارات مرشّحة
overall_f = overall[(overall["university"]==uni)].sort_values("year")
func_f = func_level[(func_level["university"]==uni)]

# ======== مساهمة الوظائف (حسب مجموع الأوزان) ========
if 'indicators_meta2' in globals() and not indicators_meta2.empty:
    type_weights = (indicators_meta2.groupby("function", as_index=False)["weight"]
                    .sum().rename(columns={"weight":"w_sum"}))
else:
    # fallback لو ما عندك indicators_meta2
    type_weights = func_f.groupby("function", as_index=False)["score"].count()
    type_weights = type_weights.rename(columns={"score":"w_sum"})

type_score_now = (func_f[func_f["year"]==current_year]
                  .groupby("function", as_index=False)["score"].mean())
type_breakdown = type_weights.merge(type_score_now, on="function", how="left").fillna({"score":0})

# ======== قيمة المؤشر الكلي للسنة الحالية ========
overall_now = overall_f.loc[overall_f["year"]==current_year, "overall_index_0_100"]
overall_now = float(overall_now.iloc[0]) if len(overall_now) else np.nan

# ======== 2) 👨‍🎓 قسم الطلاب ========
st.markdown("### 👨‍🎓 الطلاب")
students_in_range = students_df[(students_df["year"]>=year_start) & (students_df["year"]<=year_end)]
national_total_range = int(students_in_range["students"].sum()) if not students_in_range.empty else 0

uni_current_students = int(
    students_df[(students_df["university"]==uni) & (students_df["year"]==current_year)]["students"].sum()
) if not students_df.empty else 0

m1, m2, m3 = st.columns(3)
with m1:
    st.metric("إجمالي الطلاب (في النطاق المختار)", f"{national_total_range:,}")
with m2:
    st.metric(f"طلاب {uni} في {current_year}", f"{uni_current_students:,}")
with m3:
    national_current_total = int(students_df[students_df["year"]==current_year]["students"].sum()) if not students_df.empty else 0
    share = (uni_current_students / national_current_total * 100.0) if national_current_total>0 else 0.0
    st.metric("حصة الجامعة من إجمالي السنة", f"{share:.1f}%")

st.write(f"**توزيع الطلاب حسب الجامعة – {current_year}**")
students_current_year = students_df[students_df["year"]==current_year].copy()
if not students_current_year.empty:
    bar_students = px.bar(students_current_year, x="university", y="students", text="students",
                          title=f"عدد الطلاب حسب الجامعة ({current_year})")
    bar_students.update_layout(yaxis_title="عدد الطلاب", xaxis_title="الجامعة")
    bar_students.update_traces(texttemplate="%{text:,}", textposition="outside")
    st.plotly_chart(bar_students, use_container_width=True)
else:
    st.info("لا توجد بيانات طلاب للسنة الحالية.")

# ======== 3) الرسوم الرئيسية للمؤشر الكلي ========
c1, c2 = st.columns([1,1])

# 3.1 Gauge
with c1:
    st.subheader("المؤشر الكلي (0–100)")
    if pd.notna(overall_now):
        gauge = go.Figure(go.Indicator(
            mode="gauge+number",
            value=overall_now,
            number={"suffix":" / 100"},
            title={"text": f"Overall Index – {uni} ({current_year})"},
            gauge={
                "axis":{"range":[0,100]},
                "bar":{"thickness":0.2},
                "steps":[
                    {"range":[0,50],"color":"#fce4e4"},
                    {"range":[50,75],"color":"#fff3cd"},
                    {"range":[75,100],"color":"#e8f5e9"},
                ]
            }
        ))
        gauge.update_layout(height=360, margin=dict(l=20,r=20,t=50,b=10))
        st.plotly_chart(gauge, use_container_width=True)
    else:
        st.warning("لا توجد قيمة متاحة للمؤشر الكلي في السنة المحددة.")

# 3.2 Pie – مساهمة الوظائف
with c2:
    st.subheader("مساهمة الوظائف داخل المؤشر الكلي")
    pie_df = type_breakdown.copy()
    pie_df["function"] = pie_df["function"].map({
        "Leading":"Leading (إنذار مبكر)",
        "Concurrent":"Concurrent (تشخيص فوري)",
        "Lagging":"Lagging (قياس أثر)"
    }).fillna(pie_df["function"])
    pie = px.pie(pie_df, names="function", values="w_sum", hole=0.45,
                 title=f"توزيع الأوزان/المساهمة – {uni}")
    pie.update_layout(legend_title="", height=360, margin=dict(l=10,r=10,t=60,b=10))
    st.plotly_chart(pie, use_container_width=True)

# 3.3 Trend line
st.markdown("### الترند الزمني للمؤشر الكلي")
trend = overall_f[(overall_f["year"]>=year_start) & (overall_f["year"]<=year_end)].sort_values("year").copy()
if not trend.empty and trend["overall_index_0_100"].notna().any():
    line = px.line(trend, x="year", y="overall_index_0_100", markers=True,
                   title=f"تطور المؤشر الكلي – {uni}")
    line.update_layout(yaxis_title="المؤشر الكلي (0–100)", xaxis_title="السنة")
    st.plotly_chart(line, use_container_width=True)
else:
    st.info("لا توجد بيانات كافية لعرض الترند في النطاق المحدد.")
    line = None  # للحماية لاحقًا

# 3.4 بديل: أعمدة
st.markdown("### تطور المؤشر الكلي عبر السنوات (أعمدة)")
if not trend.empty and trend["overall_index_0_100"].notna().any():
    bar = px.bar(
        trend, x="year", y="overall_index_0_100",
        title=f"تطور المؤشر الكلي – {uni}", text="overall_index_0_100"
    )
    bar.update_traces(texttemplate="%{text:.1f}", textposition="outside")
    bar.update_layout(
        yaxis_title="المؤشر الكلي (0–100)",
        xaxis_title="السنة",
        uniformtext_minsize=10, uniformtext_mode='hide',
        margin=dict(l=10, r=10, t=60, b=10)
    )
    st.plotly_chart(bar, use_container_width=True)
else:
    st.info("لا توجد بيانات كافية لعرض الأعمدة.")

# 3.5 YoY
st.markdown("### التغير سنة بسنة (YoY)")
if len(trend) >= 2 and trend["overall_index_0_100"].notna().any():
    yoy = trend.copy()
    yoy["yoy_delta"] = yoy["overall_index_0_100"].diff()
    yoy = yoy.dropna(subset=["yoy_delta"])
    yoy["direction"] = np.where(yoy["yoy_delta"]>=0, "تحسن", "تراجع")
    bar_yoy = px.bar(
        yoy, x="year", y="yoy_delta", color="direction",
        color_discrete_map={"تحسن":"#2ca02c","تراجع":"#d62728"},
        title=f"التغير سنة بسنة – {uni}", text="yoy_delta"
    )
    bar_yoy.update_traces(texttemplate="%{text:.1f}", textposition="outside")
    bar_yoy.update_layout(yaxis_title="فرق النقاط عن السنة السابقة", xaxis_title="السنة")
    st.plotly_chart(bar_yoy, use_container_width=True)
else:
    st.info("يلزم توفر سنتين على الأقل لعرض التغير سنة بسنة.")

# 3.6 Sparkline + ملخص
st.markdown("### لمحة سريعة عن الاتجاه")
if not trend.empty and trend["overall_index_0_100"].notna().any():
    last = trend.iloc[-1]["overall_index_0_100"]
    prev = trend.iloc[-2]["overall_index_0_100"] if len(trend) >= 2 else np.nan
    delta = (last - prev) if pd.notna(prev) else np.nan

    k1, k2 = st.columns([1,2])
    with k1:
        st.metric("آخر قيمة", f"{last:.1f}", delta=None if pd.isna(delta) else f"{delta:+.1f}")
    with k2:
        spark = px.line(trend, x="year", y="overall_index_0_100")
        spark.update_layout(
            height=140, margin=dict(l=10,r=10,t=10,b=10),
            yaxis_title=None, xaxis_title=None
        )
        spark.update_traces(mode="lines+markers")
        st.plotly_chart(spark, use_container_width=True)

    # تمييز آخر نقطة + كتابة فروقات YoY على الخط (حماية وجود line)
    if line is not None:
        last_row = trend.iloc[-1]
        line.add_scatter(x=[last_row["year"]], y=[last_row["overall_index_0_100"]],
                        mode="markers+text", text=[f"{last_row['overall_index_0_100']:.0f}"],
                        textposition="top center", marker=dict(size=12))
        for i in range(1, len(trend)):
            x_mid = (trend.iloc[i-1]["year"] + trend.iloc[i]["year"]) / 2
            y_mid = (trend.iloc[i-1]["overall_index_0_100"] + trend.iloc[i]["overall_index_0_100"]) / 2
            dlt = trend.iloc[i]["overall_index_0_100"] - trend.iloc[i-1]["overall_index_0_100"]
            line.add_annotation(x=x_mid, y=y_mid, text=f"{dlt:+.0f}", showarrow=False, font=dict(size=12))
else:
    st.info("لا توجد بيانات كافية لعرض الملخص.")

# ======== 4) 🇸🇦 التنبؤ الوطني (موحّد) ========
st.markdown("## 🇸🇦 التنبؤ الوطني (مؤشر جاهزية موحّد)")
def build_national_series(overall_df, students_df):
    totals = (students_df.groupby("year", as_index=False)["students"]
              .sum().rename(columns={"students":"national_total"}))
    s = students_df.merge(totals, on="year", how="left")
    s["share"] = np.where(s["national_total"]>0, s["students"]/s["national_total"], 0.0)
    o = overall_df.rename(columns={"overall_index_0_100":"uni_index"})
    merged_ns = o.merge(s[["university","year","share"]], on=["university","year"], how="left")
    merged_ns["weighted"] = merged_ns["uni_index"] * merged_ns["share"]
    nat = (merged_ns.groupby("year", as_index=False)["weighted"].sum()
           .rename(columns={"weighted":"national_index"}))
    nat = nat.sort_values("year").reset_index(drop=True)
    return nat

nat = build_national_series(overall, students_df)

left_nat, right_nat = st.columns([2,1])
with left_nat:
    if not nat.empty and nat["national_index"].notna().any():
        fig_nat = px.line(nat, x="year", y="national_index", markers=True,
                          title="السلسلة الوطنية التاريخية (0–100)")
        fig_nat.update_layout(yaxis_title="المؤشر الوطني", xaxis_title="السنة")
        st.plotly_chart(fig_nat, use_container_width=True)
    else:
        st.info("لا توجد بيانات كافية لبناء السلسلة الوطنية.")

with right_nat:
    horizon = st.slider("أفق التنبؤ (بالسنوات)", 1, 5, 3)

def forecast_national(nat_df, horizon):
    y = nat_df.set_index("year")["national_index"].astype(float)
    if len(y) < 3:
        xs = np.arange(len(y))
        if len(xs) == 0:
            return nat_df.copy(), pd.DataFrame(columns=["year","forecast"])
        A = np.vstack([xs, np.ones(len(xs))]).T
        m, c = np.linalg.lstsq(A, y.values, rcond=None)[0]
        last_year = int(y.index.max())
        fut_years = [last_year + i for i in range(1, horizon+1)]
        fut_vals = [m*(len(xs)+i-1) + c for i in range(1, horizon+1)]
        fc = pd.DataFrame({"year": fut_years, "forecast": fut_vals})
        return nat_df.copy(), fc
    model = ExponentialSmoothing(y, trend='add', seasonal=None, initialization_method="estimated")
    fit = model.fit(optimized=True)
    last_year = int(y.index.max())
    fut_index = [last_year + i for i in range(1, horizon+1)]
    fc_values = fit.forecast(horizon)
    fc = pd.DataFrame({"year": fut_index, "forecast": fc_values.values})
    return nat_df.copy(), fc

if not nat.empty and nat["national_index"].notna().any():
    hist, fc = forecast_national(nat, horizon)
    nat_fc = hist.merge(fc, on="year", how="outer").sort_values("year")
    fig_fc = go.Figure()
    hist_part = nat_fc[nat_fc["national_index"].notna()]
    fig_fc.add_trace(go.Scatter(x=hist_part["year"], y=hist_part["national_index"],
                                mode="lines+markers", name="تاريخ"))
    fc_part = nat_fc[nat_fc["forecast"].notna()]
    fig_fc.add_trace(go.Scatter(x=fc_part["year"], y=fc_part["forecast"],
                                mode="lines+markers", name="تنبؤ", line=dict(dash="dash")))
    fig_fc.update_layout(title=f"تنبؤ المؤشر الوطني حتى {int(fc_part['year'].max()) if not fc_part.empty else ''}",
                         yaxis_title="المؤشر الوطني (0–100)", xaxis_title="السنة",
                         margin=dict(l=10,r=10,t=60,b=10))
    st.plotly_chart(fig_fc, use_container_width=True)

    if not fc.empty:
        st.success(
            f"**قيمة التنبؤ لسنة {int(fc.iloc[0]['year'])}: {fc.iloc[0]['forecast']:.1f}**  • "
            f"**أعلى سنة متوقعة ضمن الأفق: {int(fc.loc[fc['forecast'].idxmax(),'year'])} ({fc['forecast'].max():.1f})**"
        )
else:
    st.info("أضف/صحّح بيانات الطلاب أو المؤشرات لبناء التنبؤ الوطني.")

# ======== 5) شرح مختصر لجزء الطلاب ========
with st.expander("ماذا يضيف قسم الطلاب؟"):
    st.markdown("""
- **إجمالي الطلاب**: يعطي حجم العينة في فترة التحليل (النطاق المختار).
- **طلاب الجامعة في السنة الحالية**: يفيد في تفسير تغيّرات المؤشر (ارتفاع/انخفاض قد يرتبط بحجم الدفعة).
- **حصة الجامعة من الإجمالي**: توضح المركز النسبي والوزن الوطني في نفس السنة.
- **الرسم العمودي**: مقارنة سريعة بين الجامعات في عدد الطلاب للسنة الحالية.
""")

# ===============================
# 6) (اختياري) تكامل سريع مع Streamlit
# ===============================
# مثال بطاقات KPI للجامعة المختارة
try:
    import streamlit as st
    import plotly.express as px

    st.markdown("## 🧭 خلاصة تنفيذية")
    universities = sorted(overall["university"].unique().tolist())
    uni = st.selectbox("اختر الجامعة", universities, index=0)

    st.write(make_executive_brief(uni))

    # مصفوفة حرارية 3×5 (وظائف × اتجاهات) بحسب آخر سنة
    trends_order = ["High Upper Trend","Moderate Upper Trend","Steady","Moderate Lower Trend","High Lower Trend"]
    func_order = ["Leading","Concurrent","Lagging"]
    grid = (func_insights_df[func_insights_df["university"]==uni]
            .groupby(["function","trend5"], as_index=False).size())
    # تجهيز pivot
    heat = (grid
            .pivot(index="function", columns="trend5", values="size")
            .reindex(index=func_order, columns=trends_order).fillna(0))
    st.markdown("### 🔳 مصفوفة (الاتجاه × الوظيفة)")
    st.dataframe(heat.style.background_gradient(axis=None))

    # Drill-down: أفضل تنبيهات لكل هدف
    st.markdown("### 🔎 تنبيهات حسب الأهداف")
    goals_ = sorted(goal_level["goal"].unique().tolist())
    gsel = st.selectbox("اختر الهدف", goals_, index=0)
    subg = func_goal_insights_df[(func_goal_insights_df["university"]==uni) & (func_goal_insights_df["goal"]==gsel)]
    st.dataframe(subg.sort_values("priority_score", ascending=False)[
        ["function","trend5","latest_year","latest_score","priority","interpretation_ar","action_ar"]
    ])
except Exception as _e:
    # بيئة غير داعمة لـ Streamlit/Plotly؟ تجاهل الواجهة
    pass









# # -----------------------------
# # 5) تجميع المستويات
# # -----------------------------


# # -----------------------------
# # 6)  الداله() تستخدم عامود القيم المعياريه  (التطبيع) وقد يكون فيها عمود () حيث
# # -----------------------------

# def aggregate(df, by_cols):
#     grouped = []
#     for keys, sub in df.groupby(by_cols):
#         # 1)تحديد الاوزان والقيم
#         w = sub["weight"] if "weight" in sub else pd.Series([np.nan]*len(sub))
#         v = sub["norm_0_100"].values

#         # 2)
#         den = w.sum()
#         if den == 0:
#             raise ValueError(f"الأوزان = 0 في المجموعة {keys} → شي غلط بالبيانات")

#         val = (v @ w) / den  # حاصل ضرب داخلي ÷ مجموع الأوزان

#         # 3) بناء سجل الناتج لهذه المجموعة
#         rec = dict(zip(by_cols, keys if isinstance(keys, tuple) else (keys,)))
#         rec["score"] = val
#         grouped.append(rec)
#     return pd.DataFrame(grouped)

# # # -----------------------------
# # # 7)  هنا نريد حساب داله تجمع بين الجامعه * السنه * الهدف * الوظيفه  وهذه الدال تحسب متوسط موزونا عبر الموشرات لان ( ) يحمل وزن كل موشر
# # # -----------------------------

# # func_level = aggregate(merged, ["university","year","goal","function"])

# # # -----------------------------
# # # 8) هنا في مستوي الهدف عندنا داتا وظيفيه بلا عمود الوزن بعد اعاده تسميته ب score  لا توجد اوزان هنا تستخدم متوسط بسيط بين الدوال الثلاثه lagging + concurrent + leeading

# # # -----------------------------
# # goal_level = aggregate(func_level.rename(columns={"score":"norm_0_100"}), ["university","year","goal"])

# # overall = aggregate(goal_level.rename(columns={"score":"norm_0_100"}), ["university","year"]).rename(columns={"score":"overall_index_0_100"})

# # -----------------------------
# # 7)
# # -----------------------------
# # 1) مستوى الوظيفة داخل الهدف (weighted by indicator weights)
# func_level = (
#     merged
#     .assign(wv = merged["norm_0_100"] * merged["weight"])
#     .groupby(["university","year","goal","function"], as_index=False)
#     .agg(score_sum=("wv","sum"), wsum=("weight","sum"))
#     .assign(score = lambda d: np.where(d["wsum"]>0, d["score_sum"]/d["wsum"], np.nan))
#     .drop(columns=["score_sum"])
# )

# # 2) مستوى الهدف (weighted by total weights carried from functions)
# goal_level = (
#     func_level
#     .assign(wv = func_level["score"] * func_level["wsum"])
#     .groupby(["university","year","goal"], as_index=False)
#     .agg(score_sum=("wv","sum"), wsum=("wsum","sum"))
#     .assign(score = lambda d: np.where(d["wsum"]>0, d["score_sum"]/d["wsum"], np.nan))
#     .drop(columns=["score_sum"])
# )

# # 3) المستوى الإجمالي (weighted by total weights carried from goals)
# overall = (
#     goal_level
#     .assign(wv = goal_level["score"] * goal_level["wsum"])
#     .groupby(["university","year"], as_index=False)
#     .agg(score_sum=("wv","sum"), wsum=("wsum","sum"))
#     .assign(overall_index_0_100 = lambda d: np.where(d["wsum"]>0, d["score_sum"]/d["wsum"], np.nan))
#     .drop(columns=["score_sum","wsum"])
# )


# # -----------------------------
# # 8) إشارات الـ Leading
# # -----------------------------
# lead = func_level[func_level["function"]=="Leading"]
# signals=[]
# for (uni,goal),sub in lead.groupby(["university","goal"]):
#     s = slope({int(r["year"]):float(r["score"]) for _,r in sub.iterrows()})
#     signals.append({"university":uni,"goal":goal,"slope":s,"trend":classify_trend(s),
#                     "signal":"Early Signal" if s>=2 else ("Early Warning" if s<=-2 else "Neutral")})
# signals_df = pd.DataFrame(signals)



# # -----------------------------
# # 7) رسوم
# # -----------------------------
# latest=max(years)
# bar=goal_level[goal_level["year"]==latest].pivot(index="goal",columns="university",values="score")
# bar.plot(kind="bar",title=f"Goal Scores {latest}"); plt.ylabel("0–100"); plt.show()

# for uni in universities:
#     mat=goal_level[goal_level["university"]==uni].pivot(index="goal",columns="year",values="score")
#     plt.imshow(mat.values,aspect="auto"); plt.colorbar(label="0–100")
#     plt.title(f"Heatmap - {uni}"); plt.xticks(range(len(mat.columns)),mat.columns); plt.yticks(range(len(mat.index)),mat.index)
#     plt.show()

# # --------------------------
# # حساب المؤشر الكلي لكل نوع
# # --------------------------
# np.random.seed(42)
# if 'value' not in indicators_meta2.columns:
#     indicators_meta2['value'] = np.random.rand(len(indicators_meta2))

# indices_df = indicators_meta2.groupby('function').apply(
#     lambda x: (x['value'] * x['weight']).sum()
# ).reset_index(name='Index')

# # إضافة المؤشر الكلي
# overall_index = indices_df['Index'].sum()
# indices_df = pd.concat([indices_df, pd.DataFrame([{'function': 'Overall', 'Index': overall_index}])], ignore_index=True)

# print(indices_df)

# plt.figure(figsize=(10,6))
# colors = {'Leading':'#FFA500', 'Concurrent':'#00BFFF', 'Lagging':'#32CD32', 'Overall':'#FF69B4'}
# plt.bar(indices_df['function'], indices_df['Index'], color=[colors[t] for t in indices_df['function']])
# plt.title("Overall Index of Graduate Readiness")
# plt.ylabel("Weighted Index")
# plt.ylim(0, 1)  # إذا القيم بين 0 و 1
# plt.show()

# st.set_page_config(page_title="Overall Graduate Readiness Index", layout="wide")
# st.title("📈 الداشبورد الأول: المؤشر الكلي لجاهزية الخريجين")
# st.caption("Gauge للمؤشر الكلي • Pie لمساهمة الأنواع • Trend عبر السنوات • 👨‍🎓 عدّاد الطلاب")

# # =========================
# # 0) دوال مساعدة + بيانات افتراضية عند الحاجة
# # =========================
# def likert_to_100(x):
#     return ((x - 1.0) / 4.0) * 100.0  # 1..5 -> 0..100

# def minmax_0_100(series, higher_is_better=True):
#     s = series.astype(float)
#     mn, mx = s.min(), s.max()
#     scaled = (s - mn) / (mx - mn) * 100.0 if mx > mn else pd.Series(50.0, index=s.index)
#     return scaled if higher_is_better else 100.0 - scaled

# def weighted_mean(values, weights):
#     values = np.asarray(values, dtype=float)
#     weights = np.asarray(weights, dtype=float)
#     if np.all(np.isnan(weights)) or np.nansum(weights) == 0:
#         return float(np.nanmean(values))
#     return float(np.nansum(values * weights) / np.nansum(weights))

# def build_demo():
#     rng = np.random.default_rng(42)
#     # 30 مؤشر: 8 Leading / 7 Concurrent / 15 Lagging
#     kinds = (["Leading"]*8) + (["Concurrent"]*7) + (["Lagging"]*15)
#     weights = rng.uniform(0.5, 2.0, size=30); weights = weights / weights.sum()
#     rows = []
#     for i in range(30):
#         rows.append({
#             "indicator_id": f"IND_{i+1:02d}",
#             "name": f"Indicator {i+1}",
#             "component_details": "",
#             "component": "",
#             "weight": weights[i],
#             "function": kinds[i],
#             "goal": rng.integers(1, 5),
#             "direction": "HigherIsBetter",
#             "is_likert": bool(rng.random() < 0.25),
#         })
#     indicators_meta2 = pd.DataFrame(rows)

#     universities = ["UniA", "UniB", "UniC"]
#     years = [2021, 2022, 2023, 2024]
#     raw = []
#     for u in universities:
#         for y in years:
#             for _, r in indicators_meta2.iterrows():
#                 val = rng.uniform(2.5, 4.7) if r["is_likert"] else rng.uniform(40, 95)
#                 raw.append((u, y, r["indicator_id"], val))
#     raw_df = pd.DataFrame(raw, columns=["university","year","indicator_id","raw_value"])

#     # تطبيع 0–100 لكل مؤشر
#     norm_blocks = []
#     for ind, sub in raw_df.groupby("indicator_id"):
#         meta = indicators_meta2.loc[indicators_meta2["indicator_id"]==ind].iloc[0]
#         sub = sub.copy()
#         if meta["is_likert"]:
#             sub["norm_0_100"] = likert_to_100(sub["raw_value"])
#         else:
#             sub["norm_0_100"] = minmax_0_100(sub["raw_value"], higher_is_better=(meta["direction"]!="LowerIsBetter"))
#         norm_blocks.append(sub)
#     norm_df = pd.concat(norm_blocks, ignore_index=True)

#     merged = norm_df.merge(indicators_meta2, on="indicator_id", how="left")

#     def aggregate(df, by_cols):
#         grouped = []
#         for keys, s in df.groupby(by_cols):
#             w = s["weight"] if "weight" in s else pd.Series([np.nan]*len(s))
#             v = s["norm_0_100"].values
#             val = weighted_mean(v, w)
#             rec = dict(zip(by_cols, keys if isinstance(keys, tuple) else (keys,)))
#             rec["score"] = val
#             grouped.append(rec)
#         return pd.DataFrame(grouped)

#     func_level = aggregate(merged, ["university","year","goal","function"])
#     goal_level = aggregate(func_level.rename(columns={"score":"norm_0_100"}), ["university","year","goal"])
#     overall = aggregate(goal_level.rename(columns={"score":"norm_0_100"}), ["university","year"]).rename(columns={"score":"overall_index_0_100"})

#     # طلاب تجريبي: توزيع عشوائي واقعي
#     srows = []
#     for y in years:
#         # إجمالي وطني تقريبي لكل سنة
#         national_total = int(rng.integers(24000, 36000))
#         # نسب الجامعات
#         shares = rng.random(3); shares = shares / shares.sum()
#         for u, sh in zip(universities, shares):
#             srows.append((u, y, int(national_total * sh)))
#     students_df = pd.DataFrame(srows, columns=["university","year","students"])

#     return indicators_meta2, raw_df, func_level, goal_level, overall, students_df

# g = globals()
# need_demo = False
# try:
#     indicators_meta2 = g["indicators_meta2"]
#     raw_df = g["raw_df"]
#     func_level = g["func_level"]
#     goal_level = g["goal_level"]
#     overall = g["overall"]
# except KeyError:
#     need_demo = True

# if need_demo:
#     indicators_meta2, raw_df, func_level, goal_level, overall, students_df = build_demo()
# else:
#     # لو عندنا ملف طلاب نقدر نقرأه من هنا:
#     students_file = st.sidebar.file_uploader("📥 حمّل ملف الطلاب (students.csv)", type=["csv"])
#     if students_file is not None:
#         students_df = pd.read_csv(students_file)
#     else:
#         # في حال ما عندنا ملف زي حالتنا الحين، نصنع داتا افتراضية من الجامعات/السنوات المتاحة
#         _, _, _, _, _, students_df = build_demo()

# # =========================
# # 1) المرشّحات
# # =========================
# left, right = st.columns([1,1])
# with left:
#     universities = sorted(overall["university"].unique().tolist())
#     uni = st.selectbox("اختر الجامعة", universities, index=0)
# with right:
#     years = sorted(overall["year"].unique().tolist())
#     year_start, year_end = st.select_slider("نطاق السنوات للترند", options=years, value=(years[0], years[-1]))

# current_year = year_end

# # اطارات مرشّحة
# overall_f = overall[(overall["university"]==uni)]
# func_f = func_level[(func_level["university"]==uni)]

# # مساهمة الأنواع (حسب مجموع الأوزان)
# type_weights = indicators_meta2.groupby("function", as_index=False)["weight"].sum().rename(columns={"weight":"w_sum"})
# type_score_now = func_f[func_f["year"]==current_year].groupby("function", as_index=False)["score"].mean()
# type_breakdown = type_weights.merge(type_score_now, on="function", how="left").fillna({"score":0})

# # قيمة المؤشر الكلي
# overall_now = overall_f[overall_f["year"]==current_year]["overall_index_0_100"]
# overall_now = float(overall_now.iloc[0]) if len(overall_now) else np.nan

# # =========================
# # 2) 👨‍🎓 قسم عدّاد الطلاب
# # =========================
# st.markdown("### 👨‍🎓 الطلاب")
# # تصفية الطلاب حسب نطاق السنوات
# students_in_range = students_df[(students_df["year"]>=year_start) & (students_df["year"]<=year_end)]
# # إجمالي الطلاب (وطني) داخل النطاق
# national_total_range = int(students_in_range["students"].sum())
# # طلاب الجامعة المختارة في السنة الحالية
# uni_current_students = int(
#     students_df[(students_df["university"]==uni) & (students_df["year"]==current_year)]["students"].sum()
# ) if not students_df.empty else 0

# m1, m2, m3 = st.columns(3)
# with m1:
#     st.metric("إجمالي الطلاب (في النطاق المختار)", f"{national_total_range:,}")
# with m2:
#     st.metric(f"طلاب {uni} في {current_year}", f"{uni_current_students:,}")
# with m3:
#     # حصة الجامعة من الإجمالي في نفس السنة
#     national_current_total = int(students_df[students_df["year"]==current_year]["students"].sum())
#     share = (uni_current_students / national_current_total * 100.0) if national_current_total>0 else 0.0
#     st.metric("حصة الجامعة من إجمالي السنة", f"{share:.1f}%")

# # توزيع الطلاب على الجامعات في السنة الحالية
# st.write(f"**توزيع الطلاب حسب الجامعة – {current_year}**")
# students_current_year = students_df[students_df["year"]==current_year].copy()
# if not students_current_year.empty:
#     bar_students = px.bar(students_current_year, x="university", y="students", text="students",
#                           title=f"عدد الطلاب حسب الجامعة ({current_year})")
#     bar_students.update_layout(yaxis_title="عدد الطلاب", xaxis_title="الجامعة")
#     bar_students.update_traces(texttemplate="%{text:,}", textposition="outside")
#     st.plotly_chart(bar_students, use_container_width=True)
# else:
#     st.info("لا توجد بيانات طلاب للسنة الحالية.")

# # =========================
# # 3) Visualization المؤشر الكلي
# # =========================
# c1, c2 = st.columns([1,1])

# # 3.1 Gauge (Speedometer) للمؤشر الكلي
# with c1:
#     st.subheader("المؤشر الكلي (0–100)")
#     if pd.notna(overall_now):
#         gauge = go.Figure(go.Indicator(
#             mode="gauge+number",
#             value=overall_now,
#             number={"suffix":" / 100"},
#             title={"text": f"Overall Index – {uni} ({current_year})"},
#             gauge={
#                 "axis":{"range":[0,100]},
#                 "bar":{"thickness":0.2},
#                 "steps":[
#                     {"range":[0,50],"color":"#fce4e4"},
#                     {"range":[50,75],"color":"#fff3cd"},
#                     {"range":[75,100],"color":"#e8f5e9"},
#                 ]
#             }
#         ))
#         gauge.update_layout(height=360, margin=dict(l=20,r=20,t=50,b=10))
#         st.plotly_chart(gauge, use_container_width=True)
#     else:
#         st.warning("لا توجد قيمة متاحة للمؤشر الكلي في السنة المحددة.")

# # 3.2 Pie – مساهمة الأنواع داخل الكلي (حسب مجموع الأوزان)
# with c2:
#     st.subheader("مساهمة الأنواع داخل المؤشر الكلي")
#     pie_df = type_breakdown.copy()
#     pie_df["function"] = pie_df["function"].map({
#         "Leading":"Leading (إنذار مبكر)",
#         "Concurrent":"Concurrent (تشخيص فوري)",
#         "Lagging":"Lagging (قياس أثر)"
#     }).fillna(pie_df["function"])

#     pie = px.pie(pie_df, names="function", values="w_sum", hole=0.45,
#                  title=f"توزيع الأوزان حسب النوع – {uni}")
#     pie.update_layout(legend_title="", height=360, margin=dict(l=10,r=10,t=60,b=10))
#     st.plotly_chart(pie, use_container_width=True)

# # 3.3 Trend line – تطور المؤشر الكلي عبر السنوات
# st.markdown("### الترند الزمني للمؤشر الكلي")
# trend = overall_f[(overall_f["year"]>=year_start) & (overall_f["year"]<=year_end)].sort_values("year")
# if not trend.empty and trend["overall_index_0_100"].notna().any():
#     line = px.line(trend, x="year", y="overall_index_0_100", markers=True,
#                    title=f"تطور المؤشر الكلي – {uni}")
#     line.update_layout(yaxis_title="المؤشر الكلي (0–100)", xaxis_title="السنة")
#     st.plotly_chart(line, use_container_width=True)
# else:
#     st.info("لا توجد بيانات كافية لعرض الترند في النطاق المحدد.")


# # 3.4 بديل: عموديات مع تسميات
# st.markdown("### تطور المؤشر الكلي عبر السنوات")
# trend = overall_f[(overall_f["year"]>=year_start) & (overall_f["year"]<=year_end)].sort_values("year")
# if not trend.empty and trend["overall_index_0_100"].notna().any():
#     bar = px.bar(
#         trend, x="year", y="overall_index_0_100",
#         title=f"تطور المؤشر الكلي – {uni}", text="overall_index_0_100"
#     )
#     bar.update_traces(texttemplate="%{text:.1f}", textposition="outside")
#     bar.update_layout(
#         yaxis_title="المؤشر الكلي (0–100)",
#         xaxis_title="السنة",
#         uniformtext_minsize=10, uniformtext_mode='hide',
#         margin=dict(l=10, r=10, t=60, b=10)
#     )
#     st.plotly_chart(bar, use_container_width=True)
# else:
#     st.info("لا توجد بيانات كافية لعرض الترند في النطاق المحدد.")

# # 3.5 بديل: فروقات سنة بسنة
# st.markdown("### التغير سنة بسنة (YoY)")
# trend = overall_f[(overall_f["year"]>=year_start) & (overall_f["year"]<=year_end)].sort_values("year")
# if len(trend) >= 2 and trend["overall_index_0_100"].notna().any():
#     trend["yoy_delta"] = trend["overall_index_0_100"].diff()
#     yoy = trend.dropna(subset=["yoy_delta"])
#     # تلوين حسب موجب/سالب
#     yoy["direction"] = np.where(yoy["yoy_delta"]>=0, "تحسن", "تراجع")
#     bar_yoy = px.bar(
#         yoy, x="year", y="yoy_delta", color="direction",
#         color_discrete_map={"تحسن":"#2ca02c","تراجع":"#d62728"},
#         title=f"التغير سنة بسنة – {uni}", text="yoy_delta"
#     )
#     bar_yoy.update_traces(texttemplate="%{text:.1f}", textposition="outside")
#     bar_yoy.update_layout(yaxis_title="فرق النقاط عن السنة السابقة", xaxis_title="السنة")
#     st.plotly_chart(bar_yoy, use_container_width=True)
# else:
#     st.info("يلزم توفر سنتين على الأقل لعرض التغير سنة بسنة.")

# # 3.6 بديل: Sparkline + ملخص
# st.markdown("### لمحة سريعة عن الاتجاه")
# trend = overall_f[(overall_f["year"]>=year_start) & (overall_f["year"]<=year_end)].sort_values("year")
# if not trend.empty and trend["overall_index_0_100"].notna().any():
#     last = trend.iloc[-1]["overall_index_0_100"]
#     prev = trend.iloc[-2]["overall_index_0_100"] if len(trend) >= 2 else np.nan
#     delta = (last - prev) if pd.notna(prev) else np.nan

#     k1, k2 = st.columns([1,2])
#     with k1:
#         st.metric("آخر قيمة", f"{last:.1f}", delta=None if pd.isna(delta) else f"{delta:+.1f}")
#     with k2:
#         spark = px.line(trend, x="year", y="overall_index_0_100")
#         spark.update_layout(
#             height=140, margin=dict(l=10,r=10,t=10,b=10),
#             yaxis_title=None, xaxis_title=None
#         )
#         spark.update_traces(mode="lines+markers")
#         st.plotly_chart(spark, use_container_width=True)
# else:
#     st.info("لا توجد بيانات كافية لعرض الملخص.")

# # تمييز آخر نقطة
# last_row = trend.iloc[-1]
# line.add_scatter(x=[last_row["year"]], y=[last_row["overall_index_0_100"]],
#                  mode="markers+text", text=[f"{last_row['overall_index_0_100']:.0f}"],
#                  textposition="top center", marker=dict(size=12))

# # كتابة فروقات سنة بسنة على الخط
# for i in range(1, len(trend)):
#     x_mid = (trend.iloc[i-1]["year"] + trend.iloc[i]["year"]) / 2
#     y_mid = (trend.iloc[i-1]["overall_index_0_100"] + trend.iloc[i]["overall_index_0_100"]) / 2
#     delta = trend.iloc[i]["overall_index_0_100"] - trend.iloc[i-1]["overall_index_0_100"]
#     line.add_annotation(x=x_mid, y=y_mid, text=f"{delta:+.0f}", showarrow=False, font=dict(size=12))

# # =========================
# # 3.7 حراسة لاستخدام 'line' لاحقًا إن كانت معرفة
# # =========================
# if 'line' not in locals():
#     line = None

# # =========================
# # 3.8 🇸🇦 التنبؤ الوطني (موحّد)
# # =========================
# st.markdown("## 🇸🇦 التنبؤ الوطني (مؤشر جاهزية موحّد)")
# from statsmodels.tsa.holtwinters import ExponentialSmoothing

# # 1) نبني السلسلة الوطنية التاريخية (وزن كل جامعة بحصتها من الطلاب في نفس السنة)
# def build_national_series(overall_df, students_df):
#     # إجمالي الطلاب لكل سنة
#     totals = students_df.groupby("year", as_index=False)["students"].sum().rename(columns={"students":"national_total"})
#     # ضم حصة كل جامعة بالسنة
#     s = students_df.merge(totals, on="year", how="left")
#     s["share"] = np.where(s["national_total"]>0, s["students"]/s["national_total"], 0.0)
#     # اجلب المؤشر الكلي لكل جامعة/سنة
#     o = overall_df.rename(columns={"overall_index_0_100":"uni_index"})
#     merged = o.merge(s[["university","year","share"]], on=["university","year"], how="left")
#     merged["weighted"] = merged["uni_index"] * merged["share"]
#     nat = merged.groupby("year", as_index=False)["weighted"].sum().rename(columns={"weighted":"national_index"})
#     # تأكد من الترتيب والنعومة البسيطة
#     nat = nat.sort_values("year").reset_index(drop=True)
#     return nat

# nat = build_national_series(overall, students_df)

# left_nat, right_nat = st.columns([2,1])
# with left_nat:
#     if not nat.empty and nat["national_index"].notna().any():
#         fig_nat = px.line(nat, x="year", y="national_index", markers=True,
#                           title="السلسلة الوطنية التاريخية (0–100)")
#         fig_nat.update_layout(yaxis_title="المؤشر الوطني", xaxis_title="السنة")
#         st.plotly_chart(fig_nat, use_container_width=True)
#     else:
#         st.info("لا توجد بيانات كافية لبناء السلسلة الوطنية.")

# with right_nat:
#     horizon = st.slider("أفق التنبؤ (بالسنوات)", 1, 5, 3)

# # 2) نموذج التنبؤ (Holt-Winters بدون موسمية — سنوي)

# st.markdown("### التنبؤ 1")

# def forecast_national(nat_df, horizon):
#     y = nat_df.set_index("year")["national_index"].astype(float)
#     # إن كانت السلسلة قصيرة جدًا، استخدم ميل خطي بسيط كبديل
#     if len(y) < 3:
#         # انحدار خطي بسيط
#         xs = np.arange(len(y))
#         A = np.vstack([xs, np.ones(len(xs))]).T
#         m, c = np.linalg.lstsq(A, y.values, rcond=None)[0]
#         last_year = int(y.index.max())
#         hist = nat_df.copy()
#         fut_years = [last_year + i for i in range(1, horizon+1)]
#         fut_vals = [m*(len(xs)+i-1) + c for i in range(1, horizon+1)]
#         fc = pd.DataFrame({"year": fut_years, "forecast": fut_vals})
#         return hist, fc
#     # Holt-Winters (trend additive)
#     model = ExponentialSmoothing(y, trend='add', seasonal=None, initialization_method="estimated")
#     fit = model.fit(optimized=True)
#     last_year = int(y.index.max())
#     fut_index = [last_year + i for i in range(1, horizon+1)]
#     fc_values = fit.forecast(horizon)
#     fc = pd.DataFrame({"year": fut_index, "forecast": fc_values.values})
#     return nat_df.copy(), fc

# if not nat.empty and nat["national_index"].notna().any():
#     hist, fc = forecast_national(nat, horizon)
#     nat_fc = hist.merge(fc, on="year", how="outer").sort_values("year")
#     # رسم مشترك
#     fig_fc = go.Figure()
#     # تاريخ
#     hist_part = nat_fc[nat_fc["national_index"].notna()]
#     fig_fc.add_trace(go.Scatter(x=hist_part["year"], y=hist_part["national_index"],
#                                 mode="lines+markers", name="تاريخ"))
#     # تنبؤ
#     fc_part = nat_fc[nat_fc["forecast"].notna()]
#     fig_fc.add_trace(go.Scatter(x=fc_part["year"], y=fc_part["forecast"],
#                                 mode="lines+markers", name="تنبؤ", line=dict(dash="dash")))
#     fig_fc.update_layout(title=f"تنبؤ المؤشر الوطني حتى {int(fc_part['year'].max()) if not fc_part.empty else ''}",
#                          yaxis_title="المؤشر الوطني (0–100)", xaxis_title="السنة",
#                          margin=dict(l=10,r=10,t=60,b=10))
#     st.plotly_chart(fig_fc, use_container_width=True)

#     # بطاقة ملخص لصانع القرار
#     if not fc.empty:
#         st.success(f"**قيمة التنبؤ لسنة {int(fc.iloc[0]['year'])}: {fc.iloc[0]['forecast']:.1f}**  • "
#                    f"**أعلى سنة متوقعة ضمن الأفق: {int(fc.loc[fc['forecast'].idxmax(),'year'])} ({fc['forecast'].max():.1f})**")
# else:
#     st.info("أضف/صحّح بيانات الطلاب أو المؤشرات لبناء التنبؤ الوطني.")

# # =========================
# # 3.z توصيات سريعة لصانع القرار (Auto-insights)
# # =========================
# with st.expander("💡 ملاحظات آلية لصانع القرار"):
#     if not nat.empty and len(nat) >= 2:
#         last = nat.iloc[-1]["national_index"]
#         prev = nat.iloc[-2]["national_index"]
#         delta = last - prev
#         bullet = []
#         bullet.append(f"- **التغير السنوي الأخير**: {delta:+.1f} نقطة.")
#         if delta < 0:
#             bullet.append("- رصد تراجع سنوي؛ يُنصح بمراجعة المؤشرات **Leading** الأعلى وزنًا.")
#         else:
#             bullet.append("- تحسن سنوي؛ حافظ على برامج الكفاءة التي أثّرت إيجابًا.")
#         if 'fc' in locals() and not fc.empty:
#             nxt = fc.iloc[0]["forecast"]
#             trend_txt = "اتجاه صاعد متوقع" if nxt >= last else "اتجاه هابط/تسطيح متوقع"
#             bullet.append(f"- **أول سنة متوقعة**: {nxt:.1f} ⇒ {trend_txt}.")
#         st.markdown("\n".join(bullet))
#     else:
#         st.write("تظهر الملاحظات بعد توفر سنتين على الأقل + بناء التنبؤ.")

# # =========================
# # 4) شرح تنبؤ
# # =========================


# def simple_forecast(nat_df, horizon):
#     y = nat_df.set_index("year")["national_index"].astype(float)
#     xs = np.arange(len(y))
#     A = np.vstack([xs, np.ones(len(xs))]).T
#     m, c = np.linalg.lstsq(A, y.values, rcond=None)[0]

#     last_year = int(y.index.max())
#     fut_years = [last_year + i for i in range(1, horizon+1)]
#     fut_vals = [m*(len(xs)+i-1) + c for i in range(1, horizon+1)]

#     fc = pd.DataFrame({"year": fut_years, "forecast": fut_vals})
#     return nat_df.copy(), fc

# # =========================
# # 4) شرح مختصر
# # =========================
# with st.expander("ماذا يضيف قسم الطلاب؟"):
#     st.markdown("""
# - **إجمالي الطلاب**: يعطي حجم العينة في فترة التحليل (النطاق المختار).
# - **طلاب الجامعة في السنة الحالية**: يفيد في تفسير تغيّرات المؤشر (ارتفاع/انخفاض قد يرتبط بحجم الدفعة).
# - **حصة الجامعة من الإجمالي**: توضح المركز النسبي للجامعة ووزنها الوطني في نفس السنة.
# - **الرسم العمودي**: مقارنة سريعة بين الجامعات في عدد الطلاب للسنة الحالية.
# """)

